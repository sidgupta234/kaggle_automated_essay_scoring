{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43498ace",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c95f7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, sklearn, matplotlib.pyplot as plt, seaborn as sns\n",
    "import re\n",
    "import math\n",
    "import statistics\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#label_dict = {1.0:'A', 1.5: 'B', 2: 'C', 2.5: 'D', 3: 'E', 3.5: 'F', 4: 'G', 4.5: 'H', 5: 'I'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8448c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/train.csv')\n",
    "english_vocab_frequency =  pd.read_csv('vocabulary_data/unigram_freq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3295fe93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.0          3.0      4.0          3.0  \n",
       "1     2.5         3.0          2.0      2.0          2.5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa836703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cohesion</th>\n",
       "      <td>3911.0</td>\n",
       "      <td>3.127077</td>\n",
       "      <td>0.662542</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syntax</th>\n",
       "      <td>3911.0</td>\n",
       "      <td>3.028254</td>\n",
       "      <td>0.644399</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocabulary</th>\n",
       "      <td>3911.0</td>\n",
       "      <td>3.235745</td>\n",
       "      <td>0.583148</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phraseology</th>\n",
       "      <td>3911.0</td>\n",
       "      <td>3.116850</td>\n",
       "      <td>0.655997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grammar</th>\n",
       "      <td>3911.0</td>\n",
       "      <td>3.032856</td>\n",
       "      <td>0.699841</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conventions</th>\n",
       "      <td>3911.0</td>\n",
       "      <td>3.081053</td>\n",
       "      <td>0.671450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count      mean       std  min  25%  50%  75%  max\n",
       "cohesion     3911.0  3.127077  0.662542  1.0  2.5  3.0  3.5  5.0\n",
       "syntax       3911.0  3.028254  0.644399  1.0  2.5  3.0  3.5  5.0\n",
       "vocabulary   3911.0  3.235745  0.583148  1.0  3.0  3.0  3.5  5.0\n",
       "phraseology  3911.0  3.116850  0.655997  1.0  2.5  3.0  3.5  5.0\n",
       "grammar      3911.0  3.032856  0.699841  1.0  2.5  3.0  3.5  5.0\n",
       "conventions  3911.0  3.081053  0.671450  1.0  2.5  3.0  3.5  5.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ec34c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I think that students would benefit from learning at home,because they wont have to change and get up early in the morning to shower and do there hair. taking only classes helps them because at there house they'll be pay more attention. they will be comfortable at home.\\n\\nThe hardest part of school is getting ready. you wake up go brush your teeth and go to your closet and look at your cloths. after you think you picked a outfit u go look in the mirror and youll either not like it or you look and see a stain. Then you'll have to change. with the online classes you can wear anything and stay home and you wont need to stress about what to wear.\\n\\nmost students usually take showers before school. they either take it before they sleep or when they wake up. some students do both to smell good. that causes them do miss the bus and effects on there lesson time cause they come late to school. when u have online classes u wont need to miss lessons cause you can get everything set up and go take a shower and when u get out your ready to go.\\n\\nwhen your home your comfortable and you pay attention. it gives then an advantage to be smarter and even pass there classmates on class work. public schools are difficult even if you try. some teacher dont know how to teach it in then way that students understand it. that causes students to fail and they may repeat the class.              \""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.full_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a8dce3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think that students would benefit from learning at home,because they wont have to change and get up early in the morning to shower and do there hair. taking only classes helps them because at there house they'll be pay more attention. they will be comfortable at home.\n",
      "\n",
      "The hardest part of school is getting ready. you wake up go brush your teeth and go to your closet and look at your cloths. after you think you picked a outfit u go look in the mirror and youll either not like it or you look and see a stain. Then you'll have to change. with the online classes you can wear anything and stay home and you wont need to stress about what to wear.\n",
      "\n",
      "most students usually take showers before school. they either take it before they sleep or when they wake up. some students do both to smell good. that causes them do miss the bus and effects on there lesson time cause they come late to school. when u have online classes u wont need to miss lessons cause you can get everything set up and go take a shower and when u get out your ready to go.\n",
      "\n",
      "when your home your comfortable and you pay attention. it gives then an advantage to be smarter and even pass there classmates on class work. public schools are difficult even if you try. some teacher dont know how to teach it in then way that students understand it. that causes students to fail and they may repeat the class.              \n",
      "--- 3.977407217025757 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "dataset = pd.read_csv('data/train.csv')\n",
    "english_vocab_frequency =  pd.read_csv('vocabulary_data/unigram_freq.csv')\n",
    "english_vocab_frequency_dict =  dict(zip(english_vocab_frequency['word'], english_vocab_frequency['count']))\n",
    "#print(len(english_vocab_frequency_dict))\n",
    "oov_list = []\n",
    "total_unique_words = []\n",
    "#sentence_number = 0\n",
    "\n",
    "print(dataset['full_text'][0])\n",
    "\n",
    "def clean_dataset(dataset_row):\n",
    "    #dataset_row[\"full_text\"] = dataset_row[\"full_text\"].lower()\n",
    "    dataset_row[\"full_text\"] = dataset_row[\"full_text\"].lower()\n",
    "    dataset_row[\"full_text\"] = re.sub('[\\t\\n\\r]', ' ', dataset_row[\"full_text\"]) #Removing \\n, \\t, \\r from from full_test\n",
    "    dataset_row[\"full_text\"] = re.sub('[^0-9a-z]', ' ', dataset_row[\"full_text\"]) #Replace all symbols except a-z and 0-9 with spaces\n",
    "    dataset_row[\"full_text\"] = re.sub('\\s{2,}', ' ', dataset_row[\"full_text\"]) #Replacing two or more spaces with single space\n",
    "    dataset_row['full_text'] = dataset_row[\"full_text\"].strip() #Removing start or end of line spaces from full_test\n",
    "    return dataset_row['full_text']\n",
    "\n",
    "def avg_unique_words(dataset_row):\n",
    "    dict_ = {}\n",
    "    words = dataset_row['full_text'].split()\n",
    "    for word in words:\n",
    "        dict_[word] = 1\n",
    "        \n",
    "    return len(dict_)/len(words)\n",
    "\n",
    "def word_freq_score(dataset_row, english_vocab_frequency_dict):\n",
    "    global oov_list\n",
    "    global total_unique_words\n",
    "    freq_score = 0\n",
    "    #print(dataset_row)\n",
    "    words = dataset_row['full_text'].split()\n",
    "    global sentence_number\n",
    "    \n",
    "#     if(sentence_number%50 == 0):\n",
    "#         print(\"sentencer_number is \", sentence_number)\n",
    "#     sentence_number+=1\n",
    "    for word in words:\n",
    "#         print(word)\n",
    "        if word in english_vocab_frequency_dict:\n",
    "            #print(english_vocab_frequency[english_vocab_frequency['word'] == word])\n",
    "            total_unique_words.append(word)\n",
    "            freq_score += math.exp(1/english_vocab_frequency_dict[word])\n",
    "        else:\n",
    "            #print(word)\n",
    "            oov_list.append(word)\n",
    "            #freq_score += 1/math.log(english_vocab_frequency_dict['the'])\n",
    "            #freq_score += math.log(1/english_vocab_frequency_dict[word])\n",
    "            #print(word)\n",
    "            \n",
    "    return math.log(freq_score)\n",
    "\n",
    "def vocab_label(dataset_row):\n",
    "    return label_dict[dataset_row['vocabulary']]\n",
    "            \n",
    "dataset['full_text'] = dataset.apply(clean_dataset, axis = 1)\n",
    "dataset['text_length'] = dataset.apply(lambda x: len(x['full_text'].split()), axis = 1)\n",
    "dataset['avg_word_length'] = dataset.apply(lambda x: statistics.mean([len(i) for i in x['full_text'].split()]), axis = 1)\n",
    "dataset['avg_unique_words_per_total_words'] = dataset.apply(avg_unique_words, axis = 1)\n",
    "dataset['word_frequency_score'] = dataset.apply(lambda x: word_freq_score(dataset_row = x, english_vocab_frequency_dict = english_vocab_frequency_dict), axis = 1)\n",
    "#dataset['vocab_label'] = dataset.apply(vocab_label, axis = 1)\n",
    "end_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38e3de3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=0.23755775999754644, pvalue=2.6362115691817557e-51)\n"
     ]
    }
   ],
   "source": [
    "#dataset[['vocabulary', 'avg_word_length']].head(10)\n",
    "print(pearsonr(dataset['vocabulary'],dataset['avg_word_length']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c9747f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=-0.017353239132762925, pvalue=0.2779342989408944)\n"
     ]
    }
   ],
   "source": [
    "#dataset[['vocabulary', 'avg_word_length']].head(10)\n",
    "print(pearsonr(dataset['vocabulary'],dataset['avg_unique_words_per_total_words']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd6df514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13146"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oov_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f2ed692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1694355"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0dad63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6842"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(oov_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a3240cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14538"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(total_unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87faec80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>text_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_unique_words_per_total_words</th>\n",
       "      <th>word_frequency_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>i think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>264</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>0.496212</td>\n",
       "      <td>5.575949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>when a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>536</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>0.253731</td>\n",
       "      <td>6.282267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>dear principal if u change the school policy o...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>330</td>\n",
       "      <td>3.960606</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>5.799093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>the best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>756</td>\n",
       "      <td>4.140212</td>\n",
       "      <td>0.268519</td>\n",
       "      <td>6.628041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>234</td>\n",
       "      <td>4.076923</td>\n",
       "      <td>0.448718</td>\n",
       "      <td>5.416101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  i think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  when a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  dear principal if u change the school policy o...       3.0   \n",
       "3  003885A45F42  the best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  text_length  \\\n",
       "0     3.5         3.0          3.0      4.0          3.0          264   \n",
       "1     2.5         3.0          2.0      2.0          2.5          536   \n",
       "2     3.5         3.0          3.0      3.0          2.5          330   \n",
       "3     4.5         4.5          4.5      4.0          5.0          756   \n",
       "4     3.0         3.0          3.0      2.5          2.5          234   \n",
       "\n",
       "   avg_word_length  avg_unique_words_per_total_words  word_frequency_score  \n",
       "0         4.125000                          0.496212              5.575949  \n",
       "1         3.875000                          0.253731              6.282267  \n",
       "2         3.960606                          0.348485              5.799093  \n",
       "3         4.140212                          0.268519              6.628041  \n",
       "4         4.076923                          0.448718              5.416101  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "389555f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=0.3157396363993091, pvalue=2.906903934861895e-91)\n"
     ]
    }
   ],
   "source": [
    "print(pearsonr(dataset['vocabulary'], dataset['word_frequency_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54e14256",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[['word_frequency_score', 'avg_unique_words_per_total_words', 'avg_word_length']]\n",
    "#X = dataset[['word_frequency_score']]\n",
    "y = dataset['vocabulary']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bff30618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 0.2833280051150895\n",
      "rmse 0.29118773946360155\n",
      "309 783\n",
      "percentage correct values in test are 39.46%\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "lr_score = lr.score(X_train, y_train)\n",
    "\n",
    "# print(\"Results for Linear Regression with Train Data\")\n",
    "# print(lr_score)\n",
    "\n",
    "lr_score = lr.score(X_test, y_test)\n",
    "\n",
    "# print(\"Results for Linear Regression with Test Data\")\n",
    "# print(lr_score)\n",
    "\n",
    "y_train_predict = lr.predict(X_train)\n",
    "y_train_predict = [(round(i*2)/2) for i in y_train_predict]\n",
    "print(\"rmse\", mean_squared_error(y_train, y_train_predict))\n",
    "# y_train_list = y_train.to_list()\n",
    "\n",
    "# total = 0\n",
    "# correct = 0\n",
    "\n",
    "# for i in range(len(y_train_list)):\n",
    "#     total += 1\n",
    "#     #print(y_test[i])\n",
    "#     if(y_train_list[i] == y_train_predict[i]):\n",
    "#         correct +=1 \n",
    "#         #print(y_test_list[i], y_predict[i])\n",
    "\n",
    "# print(total, correct)\n",
    "# print(\"percentage correct values in train are {:.2f}%\".format(100*(correct/total)))\n",
    "# #print(y_predict)\n",
    "\n",
    "y_predict = lr.predict(X_test)\n",
    "y_predict = [(round(i*2)/2) for i in y_predict]\n",
    "print(\"rmse\", mean_squared_error(y_test, y_predict))\n",
    "y_test_list = y_test.to_list()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for i in range(len(y_test_list)):\n",
    "    total += 1\n",
    "    #print(y_test[i])\n",
    "    if(y_test_list[i] == y_predict[i]):\n",
    "        correct +=1 \n",
    "        #print(y_test_list[i], y_predict[i])\n",
    "\n",
    "print(correct, total)\n",
    "print(\"percentage correct values in test are {:.2f}%\".format(100*(correct/total)))\n",
    "#print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2719d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76723622, 2.73163982, 0.4717778 ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9593acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = dataset[['word_frequency_score', 'avg_unique_words_per_total_words', 'avg_word_length']]\n",
    "# y = dataset['vocab_label']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa6798c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LogisticRegression(random_state=0, max_iter=7000).fit(X_train, y_train)\n",
    "# lr_score = lr.score(X_train, y_train)\n",
    "\n",
    "# print(\"Results for Logistic Regression with Train Data\")\n",
    "# print(lr_score)\n",
    "\n",
    "# lr_score = lr.score(X_test, y_test)\n",
    "\n",
    "# print(\"Results for Logistic Regression with Test Data\")\n",
    "# print(lr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee94f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc = SVC(gamma='auto')\n",
    "# svc.fit(X_train, y_train)\n",
    "\n",
    "# svc_score = svc.score(X_train, y_train)\n",
    "\n",
    "# print(\"Results for SVM with Train Data\")\n",
    "# print(lr_score)\n",
    "\n",
    "# svc_score = svc.score(X_test, y_test)\n",
    "\n",
    "# print(\"Results for SVM with Test Data\")\n",
    "# print(svc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c60e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LogisticRegression(random_state=0, max_iter=7000).fit(X_train, y_train)\n",
    "# lr_score = lr.score(X_train, y_train)\n",
    "\n",
    "# print(\"Results for Logistic Regression with Train Data\")\n",
    "# print(lr_score)\n",
    "\n",
    "# lr_score = lr.score(X_test, y_test)\n",
    "\n",
    "# print(\"Results for Logistic Regression with Test Data\")\n",
    "# print(lr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24cc6576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40cba95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
